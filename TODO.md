# Py_artnet - TODO Liste

> **Siehe [HISTORY.md](HISTORY.md) fÃ¼r abgeschlossene Features (v1.x - v2.3)**

## ğŸš€ Geplante Features (nach KomplexitÃ¤t & PrioritÃ¤t)

Die Features sind in 6 PrioritÃ¤tsstufen organisiert basierend auf **Implementierungs-KomplexitÃ¤t** und **Business-Value**:
- **P1**: Quick Wins (niedriger Aufwand, hoher Nutzen)
- **P2**: Mittlere KomplexitÃ¤t, hoher Nutzen
- **P3**: Mittlere KomplexitÃ¤t, mittlerer Nutzen
- **P4**: Hohe KomplexitÃ¤t, hoher Nutzen
- **P5**: Niedrige PrioritÃ¤t / Maintenance
- **P6**: Optional / Langfristig

---

## ğŸ”¥ PRIORITÃ„T 1 - Quick Wins (~43-66h)
**Niedriger Aufwand, hoher Nutzen - sofort umsetzbar**

### 1.0 ğŸ¨ Unified Playlist System - Player/Playlist Generalisierung (~7-10h) ğŸ†•

**Ziel:** 100% generalisiertes Player-System - neue Player durch `playerConfigs` hinzufÃ¼gen, ohne Code-Ã„nderungen.

**Aktueller Stand:** ~60% generalisiert (Backend 99%, Frontend 60%)

- [x] **Phase 1: Legacy Variables migrieren (2h):** âœ… COMPLETED
  - `videoFiles/artnetFiles` â†’ `playerConfigs[playerId].files`
  - `currentVideoFile/currentArtnetFile` â†’ `playerConfigs[playerId].currentFile`
  - `videoAutoplay/artnetAutoplay` â†’ `playerConfigs[playerId].autoplay`
  - `videoLoop/artnetLoop` â†’ `playerConfigs[playerId].loop`
  - ~15 Funktionen betroffen (loadVideoFile, loadArtnetFile, etc.)

- [x] **Phase 2: Load-Funktionen generalisieren (2-3h):** âœ… COMPLETED
  - `loadVideoFile()` + `loadArtnetFile()` â†’ `loadFile(playerId, file)`
  - `window.loadVideoFile` + `window.loadArtnetFile` â†’ `window.loadFile`
  - Entfernt ~100 Zeilen Code-Duplikation

- [x] **Phase 3: Player Wrappers entfernen (2h):** âœ… COMPLETED
  - `toggleVideoPlay()`, `nextVideoClip()` etc. â†’ `togglePlay(playerId)`, `nextClip(playerId)`
  - Window-Wrapper durch direkte generische Calls ersetzen

- [x] **Phase 4: Backend-Hotfix (15min):** âœ… COMPLETED
  - `default_effects.py` Zeilen 115-118: Hardcoded player_type checks entfernen
  - Verwende `player.player_type` statt `isinstance()` checks

- [x] **Phase 5: Testing & Bugfixes:** âœ… COMPLETED
  - Fixed orphaned function call references
  - Exposed player control functions to window object
  - Fixed async/await syntax in drop handlers
  - Implemented transport loop detection for autoplay
  - Fixed Art-Net autoplay race conditions
  - All bugs resolved, both players fully functional

- [x] **Phase 6: v2.3.7 Legacy Code Cleanup (~6-8h):** âœ… COMPLETED (2025-12-05)
  - âœ… Removed deprecated trim/reverse functions from player.js (~300 lines)
  - âœ… Deleted 4 deprecated backend modules (~500 lines): api_clip_trim.py, api_artnet_effects_deprecated.py, api_effects_deprecated.py, api_videos_deprecated.py
  - âœ… Removed deprecated ClipRegistry methods: set_clip_trim(), set_clip_reverse(), get_clip_playback_info()
  - âœ… Removed trim/reverse logic from VideoSource (in_point, out_point, reverse properties)
  - âœ… Removed ScriptSource class completely (~100 lines) and all references from 9 modules
  - âœ… Migrated ScriptSource â†’ GeneratorSource with deprecation warnings
  - âœ… Removed legacy API fallbacks from playerConfigs
  - âœ… Removed deprecated layer management functions: updateLayerStackVisibility(), selectLayer()
  - âœ… Fixed all syntax errors introduced during cleanup (4 errors)
  - **Total Impact:** ~1000 lines of dead code removed, Transport Effect Plugin now single source of truth

- [x] **Phase 7: WebRTC â†’ WebSocket Migration (~4h):** âœ… COMPLETED (2025-12-08)
  - âœ… Created WebSocket streaming backend (`src/modules/api_websocket.py`)
  - âœ… Created WebSocket streaming frontend (`frontend/js/websocket-preview.js`)
  - âœ… Removed WebRTC backend modules (api_webrtc.py, webrtc_track.py)
  - âœ… Removed WebRTC frontend (webrtc-preview.js)
  - âœ… Updated player.js and player.html for WebSocket
  - âœ… Migrated config.json from webrtc â†’ websocket section
  - âœ… Added Socket.IO integration (Flask-SocketIO + Socket.IO client)
  - âœ… Implemented aspect-ratio-preserving canvas rendering
  - âœ… Performance optimizations: frame identity tracking, 1ms polling, fast JPEG encoding
  - âœ… Fixed disconnect handler and thread joining issues
  - **Result:** Latency reduced from ~1s to <100ms, simplified LAN-only architecture

**Vorteile:**
- Neue Player in 5min hinzufÃ¼gen (nur `playerConfigs` Entry)
- -200 Zeilen Code (keine Duplikation)
- Konsistentes Verhalten Ã¼ber alle Player
- Wartbarkeit massiv verbessert
- Cleaner codebase ohne deprecated legacy code (~1000 lines removed)

**Siehe:** [UNIFIED_PLAYLISTS.md](docs/UNIFIED_PLAYLISTS.md) fÃ¼r Details

---

### 1.1 ğŸ”„ Master/Slave Duration Sync (~3-4h) ğŸ†•

**Ziel:** Slave clips automatically loop to match master clip duration for synchronized timing.

**Concept:** When slave syncs to a clip, calculate required `loop_count` based on master's clip duration.

- [ ] **Config Option (30min):**
  - Add `master_slave.sync_slave_duration: false` to config.json
  - Add `master_slave.duration_match_tolerance: 0.5` (seconds) for rounding
  - Document config options in CONFIG_SCHEMA.md

- [ ] **Duration Calculation Method (1h):**
  - Add `_get_clip_duration(player)` to PlayerManager
  - Calculate duration from source.total_frames / source.fps
  - Handle edge cases: generators (return None), missing metadata
  - Add `_get_transport_effect(player)` helper method

- [ ] **Sync Logic Implementation (1-2h):**
  - Enhance `_sync_slave_to_index()` in player_manager.py
  - Calculate required loops: `math.ceil(master_duration / slave_duration)`
  - Apply to slave's transport.loop_count
  - Add detailed logging: "ğŸ”„ Slave duration sync: 5.0s Ã— 6 = 30.0s (master: 30.0s)"

- [ ] **Edge Case Handling (30min):**
  - Slave longer than master: Use loop_count=1, log warning
  - Generator clips: Skip duration sync, use manual loop_count
  - Missing duration data: Fallback to existing behavior
  - Zero/negative durations: Validation checks

- [ ] **Testing & Validation (30min):**
  - Test: 30s master + 5s slave = 6 loops
  - Test: 10s master + 15s slave = 1 loop (slave plays full)
  - Test: Master with generators
  - Test: Config enabled/disabled behavior

**Example Usage:**
```json
{
    "master_slave": {
        "sync_slave_duration": true
    }
}
```

**Result:**
```
Master: 30s clip, loop_count=1 â†’ plays once, advances
Slave:  5s clip, loop_count=6 (auto) â†’ loops 6 times, syncs with master
```

**Siehe:** [TRANSPORT_MASTER_SLAVE_ANALYSIS.md](docs/TRANSPORT_MASTER_SLAVE_ANALYSIS.md) Option 1

---

### 1.2 ğŸ¨ Generator Duration Support (~3-4h) âœ… COMPLETED (2025-12-08)

**Ziel:** Give generator clips a defined duration for proper loop_count and master/slave synchronization.

**Concept:** Add `duration` parameter to GeneratorSource for calculating total_frames and enabling duration-based timing.

- [x] **GeneratorSource Enhancement (2h):** âœ… COMPLETED
  - Added `duration` parameter (seconds, default 0=infinite)
  - Uses existing `fps` from FrameSource (default 30)
  - Calculates `total_frames = duration * fps` when duration > 0
  - Modified `get_next_frame()` to loop frames: `virtual_frame % total_frames`
  - Added `is_duration_defined()` method for duration sync compatibility
  - Updates `is_infinite` flag based on duration (0=infinite, >0=finite)

- [x] **Plugin System Updates (1h):** âœ… COMPLETED
  - PLUGIN_TEMPLATE.md already included duration parameter example
  - Duration auto-handled by GeneratorSource parameter system
  - Validation built-in via parameter min/max (0-600s in template)
  - All existing generators can add duration parameter to PARAMETERS array

- [x] **UI Integration (30min):** âœ… COMPLETED
  - Generator parameter UI already supports INT parameters with triple-slider
  - Duration shows as slider when added to generator's PARAMETERS
  - Range customizable via param min/max (e.g., 0-300s)
  - Value displayed automatically by existing parameter system

- [x] **Master/Slave Compatibility (30min):** âœ… COMPLETED
  - `is_duration_defined()` method ready for TODO 1.1 integration
  - When `_get_clip_duration()` is implemented in TODO 1.1, it will check this method
  - Generators with duration > 0 can be master clips
  - Duration sync (1.1) will work seamlessly with generators

**Implementation Details:**
```python
# src/modules/frame_source.py - GeneratorSource.__init__()
self.duration = parameters.get('duration', 0)  # 0 = infinite, >0 = seconds
self.is_infinite = (self.duration == 0)
if self.duration > 0:
    self.total_frames = int(self.duration * self.fps)
else:
    self.total_frames = 0  # 0 = infinite

# src/modules/frame_source.py - GeneratorSource.get_next_frame()
if self.total_frames > 0:
    virtual_frame = virtual_frame % self.total_frames  # Loop frames

# src/modules/frame_source.py - GeneratorSource.is_duration_defined()
def is_duration_defined(self):
    return self.duration > 0
```

**Usage in Generator Plugins:**
```python
# Add to PARAMETERS array
{
    'name': 'duration',
    'label': 'Duration (seconds)',
    'type': ParameterType.INT,
    'default': 0,  # 0 = infinite
    'min': 0,
    'max': 600,
    'description': 'Playback duration (0 = infinite, >0 = loop after N seconds)'
}
```

**Edge Cases:**
- duration=0: Infinite generator (default behavior)
- duration>0: Loops after total_frames reached
- Master/slave: Generators with duration can be master or calculate slave loops
- UI: Duration parameter automatically gets slider in generator parameter panel

**Benefits:**
- âœ… Generators work in master/slave duration sync (TODO 1.1)
- âœ… Predictable loop timing for playlist automation
- âœ… Frame-accurate synchronization with video clips
- âœ… Transport effect loop_count works with generators
- âœ… No changes needed to existing generators (duration optional)

**Siehe:** [TRANSPORT_MASTER_SLAVE_ANALYSIS.md](docs/TRANSPORT_MASTER_SLAVE_ANALYSIS.md) Option 3

---

### 1.3 ğŸ›ï¸ Dynamic Playlists via config.json (~8-12h) ğŸ†•

**Ziel:** Neue Playlists (Audio, DMX, OSC, MIDI, etc.) Ã¼ber config.json hinzufÃ¼gen, ohne Code zu Ã¤ndern.

- [ ] **Config Schema Definition (2h):**
  - Definiere `playlists` Array in config.json
  - Schema pro Playlist: `{id, name, type, icon, apiBase, features}`
  - Beispiel-Types: video, artnet, audio, dmx, osc, midi
  - Features-Flags: autoplay, loop, transitions, preview, effects

- [ ] **Backend Dynamic Registration (2-3h):**
  - PlayerManager liest `playlists` aus config.json
  - Dynamisches Registrieren von Playern: `for playlist in config['playlists']: register_player(playlist['id'])`
  - Player-Type-Factory: Je nach type verschiedene Player-Klassen instantiieren
  - API-Routes automatisch fÃ¼r alle konfigurierten Player verfÃ¼gbar

- [ ] **Frontend Dynamic playerConfigs (2-3h):**
  - Neuer API-Endpoint: `GET /api/player/configs` â†’ Gibt alle Player-Configs zurÃ¼ck
  - Frontend: Fetch playerConfigs from API statt hardcoded
  - playerConfigs dynamisch aus API-Response generieren
  - Backward-compatibility: Fallback auf hardcoded configs wenn API fehlt

- [ ] **Dynamic UI Generation (2-3h):**
  - HTML-Template fÃ¼r Player-Section (Mustache/Handlebars oder JS Template Literals)
  - JavaScript generiert player-sections basierend auf playerConfigs
  - Icon-Mapping: video=ğŸ“¹, artnet=ğŸ’¡, audio=ğŸ”Š, dmx=ğŸšï¸, osc=ğŸ›ï¸, midi=ğŸ¹
  - Container-IDs dynamisch: `${playerId}Playlist`, `${playerId}Preview`, etc.

- [ ] **Auto-Initialize (1h):**
  - Loop Ã¼ber alle playerConfigs: `for (let playerId in playerConfigs) { await loadPlaylist(playerId); }`
  - Event-Listeners automatisch fÃ¼r alle Player registrieren
  - Drop-Zones fÃ¼r alle Player generieren

**Config-Beispiel (config.json):**
```json
{
  "playlists": [
    {
      "id": "video",
      "name": "Video",
      "type": "video",
      "icon": "ğŸ“¹",
      "apiBase": "/api/player/video",
      "features": {
        "autoplay": true,
        "loop": true,
        "transitions": true,
        "preview": true,
        "effects": true
      }
    },
    {
      "id": "artnet",
      "name": "Art-Net",
      "type": "artnet",
      "icon": "ğŸ’¡",
      "apiBase": "/api/player/artnet",
      "features": {
        "autoplay": true,
        "loop": true,
        "transitions": true,
        "preview": true,
        "effects": true
      }
    },
    {
      "id": "audio",
      "name": "Audio",
      "type": "audio",
      "icon": "ğŸ”Š",
      "apiBase": "/api/player/audio",
      "features": {
        "autoplay": true,
        "loop": true,
        "transitions": false,
        "preview": false,
        "effects": true
      }
    }
  ]
}
```

**Vorteile:**
- Neue Player in 5min hinzufÃ¼gen (nur config.json Entry, kein Code!)
- Skalierbar auf beliebig viele Player (Audio, DMX, OSC, MIDI, etc.)
- Konsistente API fÃ¼r alle Player-Typen
- Frontend/Backend vollstÃ¤ndig entkoppelt

---

### 1.2 ğŸ¯ Playlist Master/Slave Synchronization (~8-14h) ğŸš§ IN PROGRESS

**âš ï¸ KNOWN ISSUE:** Generator clips in playlists with autoplay+loop+master/slave mode not working correctly. Need deeper investigation of generator handling in autoplay loop and slave synchronization context.

- [x] **Master/Slave Toggle UI (2h):** âœ… COMPLETED
  - Toggle-Button in Playlist-Header (Video & Art-Net)
  - Master-Indicator (ğŸ‘‘ Icon) fÃ¼r aktive Master-Playlist
  - Nur eine Playlist kann Master sein (Toggle schaltet andere aus)
  - Visuelles Feedback: Master (grÃ¼n/golden), Slave (grau/normal)
  - CSS Styling mit Switch-Animation

- [x] **Synchronization Engine (4-6h):** âœ… COMPLETED
  - Event-System: Master emittiert `clip_changed` Events mit Clip-Index
  - Slave-Listener: Reagiert auf Master-Events und wechselt zum gleichen Clip-Index
  - Initial Sync: Wenn Master aktiviert â†’ Alle Slaves springen zu Master-Clip-Index
  - Transition-Preservation: Slaves verwenden ihre eigenen Transition-Settings
  - Edge-Case Handling:
    - Slave hat weniger Clips als Master â†’ Slave stopped (black screen)
    - Master deaktiviert â†’ Slaves werden autonom
    - Playlist leer â†’ Keine Sync-Aktion

- [x] **Backend Implementation (3-4h):** âœ… COMPLETED
  - `PlayerManager`: Master/Slave State Management
  - `set_master_playlist(player_id)` â†’ Setzt Master, alle anderen zu Slaves
  - `sync_slaves_to_master()` â†’ Synchronisiert alle Slaves zum Master-Clip
  - Event-Dispatcher fÃ¼r Clip-Wechsel (Observer Pattern via `on_clip_changed()`)
  - `current_clip_index` tracking in Player
  - `load_clip_by_index()` for direct index-based clip loading

- [x] **REST API (1-2h):** âœ… COMPLETED
  - POST `/api/player/{player_id}/set_master` â†’ Aktiviert Master-Mode
  - GET `/api/player/sync_status` â†’ Gibt Master/Slave Status zurÃ¼ck
  - Unified API: Master-State in Player-Status integrieren (`is_master`, `master_playlist`, `current_clip_index`)

- [x] **Frontend Integration (2h):** âœ… COMPLETED
  - Master-Toggle-Button in Playlist-Controls (neben Autoplay/Loop)
  - Master/Slave Status-Anzeige (Icon + Farbe)
  - API-Calls fÃ¼r Toggle-Actions
  - Visual Feedback bei Sync-Aktionen (grÃ¼ner Rahmen auf aktiven Clip)
  - `updateMasterUI()` fÃ¼r visuelles Feedback
  - `pollSyncStatus()` fÃ¼r real-time Updates

**Funktionsweise:**
```
MASTER (Video Playlist):     [Clip1] [Clip2] [Clip3] [Clip4] â† Master aktiviert
                                                      â†“ Clip 4 aktiv
SLAVE (Art-Net Playlist):    [Clip1] [Clip2] [Clip3] [Clip4] â†’ Springt zu Clip 4
                                                      â†‘ Sync!

Master â†’ Clip 5:             [Clip5] wird geladen
Slave:                       â†’ Wechselt auch zu Clip 5 (sofort, mit eigener Transition)
```

**Vorteile:**
- Synchrone Shows mit mehreren Outputs (Video + Art-Net)
- Verschiedene Clips auf verschiedenen AusgÃ¤ngen, aber synchroner Ablauf
- Master/Slave kann jederzeit gewechselt werden
- Jede Playlist behÃ¤lt ihre eigenen Effekte/Transitions

---

### 1.2 ğŸ”Œ Plugin-System erweitern (~8-12h) âœ… COMPLETED (2025-12-07)

- [x] **Layer-Effekte Ã¼ber Clip FX Tab (8-12h):** âœ… COMPLETED
  - âœ… API-Endpoints fÃ¼r Layer-Effekte (Unified API: `/api/player/{player_id}/clip/{clip_id}/effects`)
  - âœ… Layer-Selection-Logik: Layer-as-Clips Architecture (jedes Layer hat eigene clip_id)
  - âœ… Clip FX Tab: Zeigt Layer-Effekte wenn Layer ausgewÃ¤hlt (via selectedLayerClipId)
  - âœ… API-Calls automatisch korrekt geroutet (targetClipId = selectedLayerClipId || selectedClipId)
  - âœ… Drag & Drop von Effekten funktioniert fÃ¼r Clip UND Layer
  - âœ… Backend: apply_layer_effects() vollstÃ¤ndig integriert, Layer.effects Array populiert
  - âœ… Live-Effekt-Instanzen: API gibt live Parameter von aktiven Layer-Instanzen zurÃ¼ck
  - âœ… UnabhÃ¤ngige Layer-Effekte: Jedes Layer hat eigene Effekt-Instanzen (z.B. Transport, Transform)
  - âœ… Parameter-Updates: Direkte Updates auf live Layer-Effekt-Instanzen (nicht Registry)
  - âœ… Transport-Plugin: Timeline-Erkennung funktioniert pro Layer, Trim-Points persistieren
  - âœ… Opacity-Persistence: Layer-Opacity bleibt erhalten Ã¼ber Transport-Loops
  - **Key Fixes:**
    - API findet aktive Layer by clip_id und updated live Effekt-Instanzen
    - Transport prioritisiert layer.source Ã¼ber player.source fÃ¼r unabhÃ¤ngige Kontrolle
    - Keine unnÃ¶tigen Layer-Reloads mehr (nur bei Clip-Wechsel, nicht bei Parameter-Updates)
    - Timeline auto-adjusts nur bei Default-Werten [0,100], respektiert User-Trim-Points

---

### 1.3 âš¡ WebSocket Command Channel - Zeitkritische Commands (~6-8h) ğŸ”¥ ğŸš§ IN PROGRESS

**Problem:** Polling-Intervalle (250-3000ms) verursachen Latenz bei zeitkritischen Operationen.

**LÃ¶sung:** Hybrid-Ansatz - REST fÃ¼r Daten-Operations, WebSocket fÃ¼r Commands & Live-Updates.

#### Endpoints nach Mehrwert (absteigend):

**ğŸ”¥ TIER 1 - Maximaler Mehrwert (Command Latency: ~50ms â†’ ~2-5ms)**

- [ ] **Effect Parameter Updates (Live-Controls):**
  - `PUT /api/player/{id}/effects/{index}/parameter` â†’ `ws://effect.param.update`
  - Aktuell: 500ms Polling fÃ¼r Live-Parameter (Brightness, Hue, etc.)
  - Mit WS: Instant bidirektionales Feedback (<5ms)
  - **Mehrwert: 100x schneller, 10x weniger Server-Load**

- [ ] **Layer Opacity/Blend Mode Updates:**
  - `PATCH /api/player/{id}/layers/{layer_id}` â†’ `ws://layer.update`
  - Aktuell: HTTP Request pro Slider-Change (50-200ms Latency)
  - Mit WS: Real-time slider sync (<5ms)
  - **Mehrwert: Smooth UI, keine Lag-Spikes**

- [ ] **Transport Controls (Play/Pause/Stop/Next/Prev):**
  - `POST /api/player/{id}/play|pause|stop|next|previous` â†’ `ws://player.command`
  - Aktuell: 20-100ms HTTP Round-Trip
  - Mit WS: <5ms Command Execution
  - **Mehrwert: Instant Response, MIDI/OSC-ready**

**ğŸŸ¡ TIER 2 - Hoher Mehrwert (Status Polling: 2000ms â†’ Event-driven)**

- [ ] **Player Status Broadcast:**
  - `GET /api/player/{id}/status` â†’ `ws://player.status` (Push statt Poll)
  - Aktuell: 2s Polling-Intervall (status_broadcast_interval)
  - Mit WS: Event-driven Updates bei Ã„nderungen
  - **Mehrwert: 90% weniger Requests, instant UI-Updates**

- [ ] **Effect Chain Updates:**
  - `GET /api/player/{id}/effects` â†’ `ws://effects.changed`
  - Aktuell: 2s Polling fÃ¼r Effect-List-Refresh
  - Mit WS: Nur bei Add/Remove/Reorder Events
  - **Mehrwert: 95% weniger Traffic**

- [ ] **Clip Progress Updates:**
  - `GET /api/player/{id}/status` (current_frame) â†’ `ws://clip.progress`
  - Aktuell: 2s Polling fÃ¼r Trim-Slider-Sync
  - Mit WS: Real-time Progress (10-30 FPS)
  - **Mehrwert: Smooth Progress-Bars**

**ğŸŸ¢ TIER 3 - Mittlerer Mehrwert (Optimierung statt Latenz)**

- [ ] **Playlist Updates:**
  - `GET /api/player/{id}/playlist` â†’ `ws://playlist.changed`
  - Aktuell: 500ms Polling bei Autoplay (nur aktiv wenn autoplay enabled)
  - Mit WS: Event bei Clip-Wechsel
  - **Mehrwert: 80% weniger Requests bei Autoplay**

- [ ] **Console/Log Streaming:**
  - `GET /api/logs` â†’ `ws://logs.stream`
  - Aktuell: 3s Polling + throttled fetch
  - Mit WS: Real-time Log-Streaming
  - **Mehrwert: Live-Debugging, keine Polling-Delay**

**âŒ NICHT WebSocket (bleiben REST):**
- File Operations (Upload, Convert, List) - zu groÃŸe Payloads
- Configuration Changes - selten, keine Latenz-Kritik
- Playlist Save/Load - Daten-Operations, kein Live-Update
- Plugin/Generator Discovery - Einmalig beim Laden

#### Implementation Plan:

1. **Backend WebSocket Server (2h):**
   - Flask-SocketIO bereits vorhanden (rest_api.py:285)
   - Neue Namespaces: `/player`, `/effects`, `/layers`
   - Event-Emitter in Player-Klasse integrieren

2. **Frontend WebSocket Client (2h):**
   - `common.js` Socket.IO Connection erweitern
   - Event-Listener fÃ¼r Commands (Tier 1)
   - Auto-Reconnect & Fallback zu REST

3. **Hybrid Routing Layer (1h):**
   - `isSocketConnected()` Check vor Command
   - Fallback: WS failed â†’ REST Request
   - Progressive Enhancement

4. **Testing & Rollout (1-2h):**
   - Latency Benchmarks (vorher/nachher)
   - Concurrent User Tests
   - Graceful Degradation Tests

**Expected Results:**
- Command Latency: 50-100ms â†’ 2-5ms (**20-50x schneller**)
- Server Load: -85% bei Status/Effect-Requests
- UI Responsiveness: Instant Feedback fÃ¼r alle Controls
- Production-Ready: MIDI/OSC Controller Support mÃ¶glich

---

### 1.4 ğŸ¬ Playlist-Sequenzer (~8-12h)

- [ ] **Show-Editor UI (4h):**
  - Liste von Clips mit Drag & Drop
  - Clip-Properties: Video/Script, Duration, Transition, Brightness

- [ ] **Persistence (2h):**
  - Save/Load Show-Dateien (JSON `.fluxshow`)
  - Show-Library (Liste aller Shows)

- [ ] **Playback Engine (4h):**
  - Sequential Playback mit Transitions
  - Cue-System (Next Cue, Jump to Cue N)
  - Loop-Mode

- [ ] **REST API (2h):**
  - GET/POST/PUT/DELETE `/api/sequencer/shows`
  - POST `/api/sequencer/play`, `/api/sequencer/stop`
  - POST `/api/sequencer/cue/<index>`

**JSON-Format Beispiel:**
```json
{
  "name": "Halloween Show 2025",
  "clips": [
    {"type": "video", "source": "kanal_1/intro.mp4", "duration": 15, "transition": "fade", "brightness": 1.0},
    {"type": "script", "source": "plasma", "duration": 30, "transition": "cut"}
  ],
  "loop": true
}
```

---

### 1.5 ğŸ›ï¸ Dynamische Parameter Sequenzen (~6-10h) ğŸ†•

- [ ] **Automatisierte Parameter-Modulation Ã¼ber verschiedene Sequenz-Typen:**
  - **Grundidee:** Parameter kÃ¶nnen zeitbasierte Sequenzen abspielen statt statischer Werte
  - **UI-Konzept:**
    ```
    âš™ï¸ Parameter [Blur Strength: 5.0] |--â–¼----|-------â–¼--|
     â”” Sequenz-Modus: [Dropdown â–¼]
          âŠ™ Manual (statisch)
          âŠ™ Audio Reactive
          âŠ™ Timeline
          âŠ™ Envelope
          âŠ™ LFO (Low-Frequency Oscillator)
    ```

- [ ] **Sequenz-Typen (6-8h):**
  
  - **Audio Reactive (2h):**
    - Bind Parameter an Audio-Feature (RMS, Peak, Bass, Mid, Treble, BPM)
    - Range-Mapping: Audio-Level (0-1) â†’ Parameter-Range (min-max)
    - Smoothing-Filter: Attack/Release fÃ¼r sanfte ÃœbergÃ¤nge
    - Threshold: Nur triggern wenn Audio Ã¼ber Schwellwert
    - UI: Spektrum-Visualisierung + Live-Wert-Anzeige
  
  - **Timeline (2h):**
    - Keyframe-basierte Timeline (Zeit â†’ Wert Paare)
    - Linear/Bezier/Step Interpolation zwischen Keyframes
    - Loop-Modes: Once, Loop, Ping-Pong
    - Sync mit Clip-Time oder Global-Time
    - UI: Mini-Timeline-Editor mit Keyframe-Punkten
  
  - **Envelope (1-2h):**
    - ADSR (Attack, Decay, Sustain, Release) Envelope
    - Trigger-Modes: On-Load, On-Beat, Manual
    - Duration & Curve-Shape pro Phase
    - UI: Visual ADSR-Curve mit Drag-Handles
  
  - **LFO (1-2h):**
    - Waveforms: Sine, Triangle, Square, Sawtooth, Random
    - Frequency (Hz) & Amplitude Control
    - Phase-Offset fÃ¼r mehrere LFOs sync
    - UI: Live-Waveform-Preview

- [ ] **Backend Implementation (2-3h):**
  - `ParameterSequencer` Klasse mit Sequenz-Engine
  - `SequencePlayer` pro Parameter-Binding
  - Integration in Effect-Pipeline (Parameter-Update-Loop)
  - Persistence: Sequenz-Config in Effect-Metadata
  - API: CRUD fÃ¼r Parameter-Sequenzen

- [ ] **REST API (1h):**
  - POST `/api/effects/{effect_id}/params/{param_name}/sequence` â†’ Bind Sequenz
  - GET `/api/effects/{effect_id}/params/{param_name}/sequence` â†’ Get Sequenz-Config
  - DELETE `/api/effects/{effect_id}/params/{param_name}/sequence` â†’ Unbind (zurÃ¼ck zu Manual)
  - PUT `/api/effects/{effect_id}/params/{param_name}/sequence` â†’ Update Sequenz-Settings

- [ ] **Frontend UI (2-3h):**
  - Sequenz-Button neben jedem Parameter (âš™ï¸ Icon)
  - Modal/Sidebar fÃ¼r Sequenz-Editor
  - Type-Selector (Dropdown: Manual/Audio/Timeline/Envelope/LFO)
  - Type-spezifische Controls (Range-Mapper, Timeline-Editor, ADSR-Curve)
  - Live-Preview: Zeigt aktuellen modulierten Wert in Echtzeit
  - Visual Feedback: Parameter-Name wird farbig wenn Sequenz aktiv

**Use-Cases:**
- Audio-reactive Blur/Brightness (pulst mit Musik)
- Timeline-basierte Color-Shifts fÃ¼r exakte Timing-Kontrolle
- ADSR-Envelope fÃ¼r Impact-Effekte (z.B. Flash bei Beat)
- LFO fÃ¼r organische Bewegungen (z.B. wabernde Transforms)

**Config-Beispiel:**
```json
{
  "effect_id": "blur_01",
  "parameter_sequences": {
    "strength": {
      "type": "audio_reactive",
      "audio_feature": "bass",
      "range": {"min": 0.0, "max": 10.0},
      "smoothing": {"attack": 0.1, "release": 0.3}
    },
    "brightness": {
      "type": "lfo",
      "waveform": "sine",
      "frequency": 0.5,
      "amplitude": 0.3,
      "offset": 0.7
    }
  }
}
```

**Vorteile:**
- Lebendige, dynamische Effekte statt statischer Parameter
- Musik-synchrone Visuals ohne manuelle Automation
- Wiederverwendbare Sequenz-Presets
- Echtzeit-Modulation ohne Performance-Impact

---

### 1.6 ğŸ¹ MIDI-over-Ethernet Support (~6-10h)

- [ ] **MIDI Control via Ethernet (minimale Latenz) (6-10h):**
  - **Grundidee:** MIDI-Signale Ã¼ber Ethernet statt USB fÃ¼r <5ms Latenz
  - **WebSocket-MIDI (empfohlen):**
    - Web-MIDI API (Browser nativ)
    - Bidirektional (Server â†’ Client Feedback)
    - <5ms Latenz (LAN), <20ms (WiFi)
  - **RTP-MIDI (optional):**
    - Standard-Protokoll (Apple MIDI-Network)
    - UDP-basiert (noch niedriger Latenz)
  - **Features:**
    - MIDI-Learn: Click auf Parameter â†’ nÃ¤chster MIDI-Input wird gemappt
    - Multi-Controller: Mehrere MIDI-GerÃ¤te gleichzeitig
    - Feedback: LED-Status zurÃ¼ck an Controller
    - Curve-Mapping: Linear, Exponential, Logarithmic
  - **Implementierung:**
    - Phase 1: WebSocket-MIDI-Handler (~2h)
    - Phase 2: MIDI-Mapping-Engine (~2h)
    - Phase 3: MIDI-Learn UI (~2h)
    - Phase 4: Client-Library (Browser) (~1h)
    - Phase 5: Feedback-System (~1h)
    - Phase 6: RTP-MIDI Support (optional) (~2h)

---

## âš¡ PRIORITÃ„T 2 - Mittel-Komplex, Hoch-Wert (~48-72h)
**Mittlerer bis hoher Aufwand, hoher Performance-Gewinn & Skalierbarkeit**

### 2.1 âš¡ WebSocket Command Channel (~4-6h) ğŸ”¥ PRIORITY

- [ ] **Zeitkritische Commands Ã¼ber WebSocket (Hybrid-Ansatz):**
  - **Problem mit REST:** 10-50ms Latenz pro Request
  - **WebSocket-Vorteile:** 2-5ms Latenz (LAN), Persistent Connection
  - **Architektur-Entscheidung:**
    - âœ… **WebSocket fÃ¼r Commands** (sofortiger Mehrwert)
    - â¸ï¸ **WebRTC fÃ¼r Video** spÃ¤ter optional (nur bei CPU-Problemen)
  - **Zeitkritische Commands:**
    - Playback: play, pause, stop, seek
    - Parameter: brightness, speed, effect_param
    - Blackout: sofortiger Blackout-Toggle
  - **Features:**
    - Auto-Reconnect bei Verbindungsabbruch
    - Event-basiert (einfach erweiterbar)
    - Broadcast an alle Clients (Multi-User)
    - Command-Queue mit Priority-System
    - Batch-Commands
    - MessagePack Support (optional)
  - **Implementierung:**
    - Phase 1: Flask-SocketIO Integration (~1h)
    - Phase 2: WebSocket Command Handler (~2h)
    - Phase 3: Command-Queue & Priority (~1h)
    - Phase 4: Client-Library (JavaScript) (~1h)
    - Phase 5: MessagePack Support (optional) (~1h)
  - **Latenz-Verbesserung:**
    - REST: 10-50ms â†’ WebSocket: 2-5ms (LAN)
    - Responsiveness-Gewinn: 5-25x schneller

**Code-Beispiel:**
```javascript
// Vorher (REST): 15-50ms Latenz
await fetch('/api/player/video/play', {method: 'POST'});

// Nachher (WebSocket): 2-5ms Latenz
socket.emit('player.play', {player_id: 'video'});
socket.on('player.status', (data) => console.log(data));
```

---

### 2.2 ğŸ–¥ï¸ Multi-Video Render Cluster (~40-60h)

- [ ] **Synchronisierte Multi-Server-Architektur fÃ¼r skalierbare Video-Ausgabe:**
  - **Grundidee:** Mehrere Render-Nodes (PCs/Server) fÃ¼r parallele Video-Displays
  - **Architektur Pattern:** Master-Slave Cluster mit WebSocket Command Sync
  
- [ ] **Core Features:**
  - **Cluster Manager (8-12h):**
    - Node Discovery (mDNS/Broadcast)
    - Health Checks & Auto-Failover
    - Leader Election (Raft-Ã¤hnlich)
    - Cluster Status Dashboard
  
  - **Command Sync Engine (10-15h):**
    - WebSocket Command Broadcast (Master â†’ Slaves)
    - Timestamp-ordered Render Queue
    - Command Deduplication & Validation
    - Retry Logic & Acknowledgments
  
  - **State Replication (8-12h):**
    - Full State Snapshot (on Node Join)
    - Delta Updates (incremental sync)
    - MVCC (Multi-Version Concurrency Control)
    - Conflict Resolution
  
  - **Render Synchronization (8-12h):**
    - NTP Time Sync Integration (Â±1ms accuracy)
    - Frame Target Calculation (`target_time = base_time + frame_index * frame_duration`)
    - VSync Lock Mode (GPU waits on VSync for <1ms jitter)
    - Drift Monitoring & Correction
  
  - **Monitoring & Debugging (6-9h):**
    - Cluster Dashboard (Node Status, Network Lag, Frame Drift)
    - Performance Metrics (FPS per Node, Sync Jitter)
    - Command History & Replay
    - Network Topology Visualization

- [ ] **Technical Details:**
  - **Sync Mechanism:**
    ```python
    # Master broadcasts command:
    {
      "type": "render.frame",
      "timestamp": 1733404800.500,  # NTP-synchronized time
      "frame_index": 1234,
      "player_state": {...},
      "effect_params": {...},
      "vsync_lock": true  # GPU waits on VSync
    }
    # Slaves execute at exact timestamp
    ```
  
  - **Latency Budget:**
    - WebSocket Broadcast: 2-10ms (LAN)
    - NTP Sync Accuracy: Â±1ms
    - VSync Jitter: <1ms (hardware-accelerated)
    - **Total System Jitter: <11ms** (acceptable for live shows)
  
  - **Video Output Scaling:**
    - Modern GPU: 4-8 HDMI/DP outputs per card
    - 4 Render Nodes Ã— 4 Outputs = **16 synchronized displays**
    - 10 Render Nodes Ã— 8 Outputs = **80 synchronized displays**
  
  - **Advantages over Art-Net Clustering:**
    - âœ… VSync hardware sync (<1ms jitter vs Art-Net 44Hz limitations)
    - âœ… Zero network overhead for frame data (each node renders locally)
    - âœ… Higher resolution (4K per display vs 512 DMX channels)
    - âœ… Simpler implementation (GPU driver handles sync)

- [ ] **Use Cases:**
  - Massive video walls (16-64+ synchronized displays)
  - Multi-projector mapping with edge blending
  - Immersive environments (360Â° projections, domes)
  - Mixed output (video displays + Art-Net LED strips hybrid)
  - Corporate installations (distributed campus displays)

- [ ] **Configuration Example:**
  ```json
  {
    "cluster": {
      "mode": "master",  // or "slave"
      "master_address": "192.168.1.100:5001",
      "node_id": "render_node_1",
      "sync": {
        "ntp_server": "pool.ntp.org",
        "vsync_lock": true,
        "max_drift_ms": 5
      },
      "outputs": [
        {"id": "HDMI-1", "resolution": "1920x1080", "position": [0, 0]},
        {"id": "HDMI-2", "resolution": "1920x1080", "position": [1920, 0]},
        {"id": "DP-1", "resolution": "3840x2160", "position": [3840, 0]}
      ]
    }
  }
  ```

- [ ] **Implementation Phases:**
  - Phase 1: Cluster Manager & Node Discovery (8-12h)
  - Phase 2: Command Sync Engine (10-15h)
  - Phase 3: State Replication (8-12h)
  - Phase 4: Render Sync & NTP Integration (8-12h)
  - Phase 5: Monitoring Dashboard (6-9h)

**Rationale:** Strategisch wichtig fÃ¼r groÃŸe Installationen. Video-Clustering ist BESSER als Art-Net-Clustering aufgrund Hardware-Sync, null Netzwerk-Overhead fÃ¼r Frames, und hÃ¶here AuflÃ¶sung. Kommt nach P1 (Basis-Features) und P2 (Master/Slave fÃ¼r einzelne Instanz).

---

### 2.3 ğŸŒ Multi-Network-Adapter Support (~4-6h)

- [ ] **Separate Netzwerk-Interfaces:**
  - **Grundidee:** Control-Traffic (API) getrennt von Art-Net-Output
  - **Features:**
    - API-Binding auf spezifisches Interface
    - Art-Net-Routing: Universes auf verschiedenen Adaptern
    - Multi-Art-Net: Mehrere Art-Net-Netzwerke parallel
    - Failover: Automatischer Switch auf Backup-Adapter
  - **Use-Cases:**
    - Adapter 1: Management (192.168.1.x)
    - Adapter 2: Art-Net Output 1 (10.0.0.x)
    - Adapter 3: Art-Net Output 2 (10.0.1.x)
  - **Implementierung:**
    - Phase 1: Network-Interface-Discovery (~1h)
    - Phase 2: API-Binding-Config (~1h)
    - Phase 3: Art-Net Multi-Adapter-Routing (~2h)
    - Phase 4: UI (Network-Adapter-Auswahl) (~1h)

**Config-Beispiel:**
```json
{
  "network": {
    "api": {"bind_address": "192.168.1.10", "port": 5000},
    "artnet": {
      "adapters": [
        {"interface": "10.0.0.50", "universes": [1,2,3,4,5]},
        {"interface": "10.0.1.50", "universes": [6,7,8,9,10]}
      ]
    }
  }
}
```

---

## ğŸ”§ PRIORITÃ„T 3 - Mittel-Komplex, Mittel-Wert (~39-57h)
**Mittlerer Aufwand, mittlere Business-PrioritÃ¤t**

### 3.1 ğŸ¥ WebRTC Video Preview âœ… COMPLETED (~8h)

- [x] **Hardware-beschleunigtes Video-Streaming:** âœ… COMPLETED (2025-12-08)
  - **Performance Improvement:**
    - CPU Usage: 40-60% â†’ 5-10% (**10x reduction**)
    - Bandwidth: 2-5 Mbps â†’ 0.2-1 Mbps (**5x reduction**)
    - Latency: 100-200ms â†’ <100ms (**2x faster**)
  - **Implemented Features:**
    - âœ… Hardware-accelerated H.264 encoding (GPU via aiortc)
    - âœ… Multi-Quality: Low (360p, 15fps), Medium (720p, 20fps), High (1080p, 30fps)
    - âœ… Adaptive FPS control (10-30 FPS)
    - âœ… Connection limit: Max 5 concurrent preview clients
    - âœ… Automatic MJPEG fallback on WebRTC failure
    - âœ… UI controls: Quality selector + mode toggle
    - âœ… Real-time stats display (FPS + bandwidth)
    - âœ… WebRTC signaling API (/api/webrtc/offer, /api/webrtc/close, /api/webrtc/stats)
    - âœ… Full documentation (docs/WEBRTC_PREVIEW.md)
  - **Backend Implementation:**
    - `src/modules/webrtc_track.py`: PlayerVideoTrack class
    - `src/modules/api_webrtc.py`: WebRTC signaling endpoints
    - Integration with rest_api.py
  - **Frontend Implementation:**
    - `frontend/js/webrtc-preview.js`: WebRTCPreview class
    - Integration in player.js + player.html
    - Quality selector dropdown
    - Mode toggle button (WebRTC â†” MJPEG)
    - Live stats display
  - **Testing:**
    - Verify WebRTC connection establishes
    - Test quality switching (requires reconnection)
    - Test automatic MJPEG fallback
    - Monitor CPU/bandwidth improvements

---

### 3.2 ğŸµ Audio-Reactive Support (~10-14h)

- [ ] **Audio-Input (4h):**
  - Microphone-Input (pyaudio/sounddevice)
  - System-Audio-Capture (WASAPI Loopback)
  
- [ ] **Audio-Analyse (3h):**
  - FFT (Bass/Mid/Treble Frequenz-BÃ¤nder)
  - BPM-Detection (tempo tracking)
  - Onset-Detection (Beat-Trigger)
  
- [ ] **Reaktive Parameter (3h):**
  - Brightness â† RMS/Peak-Level
  - Speed â† BPM
  - Color â† Frequenz-Mapping
  - Effect-Intensity â† Audio-Level
  
- [ ] **UI & API (2h):**
  - Audio-Device-Auswahl
  - Live-Spektrum-Anzeige
  - Parameter-Mapping-Editor

---

---

## ğŸš€ PRIORITÃ„T 4 - Hoch-Komplex, Hoch-Wert (~48-76h)
**Hoher Aufwand, strategisch wichtig**

### 4.1 ğŸ”® Neue Frame Sources (~12-20h)

- [ ] **ShaderToy Source (8-12h):**
  - ModernGL/PyOpenGL Integration
  - GLSL Shader Support (Shadertoy-kompatibel)
  - Uniform Variables (iTime, iResolution, iMouse)

- [x] **LiveStream Source (2-5h):** âœ… COMPLETED
  - RTSP/HTTP/HLS/RTMP Stream Support
  - FFmpeg Integration via OpenCV
  - YouTube URL Support (yt-dlp)

---

### 4.2 ğŸ¥ Projection Mapping Support (~16-24h)

- [ ] **Projection Mapping System (16-24h):**
  - **Grundidee:** Video-Content auf reale Objekte projizieren mit Warp & Blend
  - **Projektor-Kalibrierung:**
    - Corner-Pin: 4-Punkt-Perspektiven-Korrektur
    - Mesh-Warping: Grid-basierte Verzerrung (z.B. fÃ¼r gekrÃ¼mmte FlÃ¤chen)
    - Auto-Alignment: Marker-Detection fÃ¼r automatische Kalibrierung
    - Multi-Projektor-Setup: Overlap-Bereiche definieren
  - **Edge-Blending:**
    - Soft-Edge-Overlap: Sanfter Ãœbergang zwischen Projektoren
    - Brightness-Matching: Angleichung der Helligkeit in Overlap-Bereichen
    - Color-Matching: Farbkalibrierung zwischen Projektoren
    - Feather-Width: Konfigurierbare Blending-Zone (0-20% Overlap)
  - **Projection Zones:**
    - Zone-Definition: Mehrere Projektions-Bereiche pro Projektor
    - Content-Mapping: Verschiedene Videos pro Zone
    - Layer-Support: Mehrere Layer pro Zone mit Compositing
    - Mask-Support: Alpha-Masken fÃ¼r Zone-Grenzen
  - **Beamer-Stacking:**
    - Brightness-Boost: Mehrere Projektoren auf gleiche FlÃ¤che
    - HDR-Simulation: Stacking fÃ¼r hÃ¶heren Kontrast
    - Sync-Modes: Frame-Lock zwischen gestackten Projektoren
    - Alignment-Tools: Pixel-genaue Ausrichtung
  - **Visualisierung & Setup:**
    - Separate HTML-Page: `projection-mapper.html`
    - Live-Preview mit Warping
    - Test-Pattern-Generator (Grid, Circles, Checkerboard)
    - Export/Import von Projection-Setups
  - **Implementierung:**
    - Phase 1: Corner-Pin & Mesh-Warp Engine (~3h)
    - Phase 2: Edge-Blending Algorithm (~3h)
    - Phase 3: Multi-Projektor-Routing (~2h)
    - Phase 4: Beamer-Stacking Support (~2h)
    - Phase 5: Projection Zone Management (~3h)
    - Phase 6: UI (Mapping-Editor, Test-Patterns) (~4h)
    - Phase 7: API-Endpoints (Setup CRUD) (~2h)

**Use-Cases:**
- GebÃ¤ude-Projektionen (Facade-Mapping)
- Theater & BÃ¼hnen-Projektionen
- Event-Installationen mit Multi-Projektor-Setups
- Museum-Installationen (Objekt-Projektionen)
- Immersive Environments (360Â° Projektionen)

**Config-Beispiel:**
```json
{
  "projection_mapping": {
    "projectors": [
      {
        "id": "proj_left",
        "output": "strip_1",
        "corner_pin": [[0,0], [1920,0], [1920,1080], [0,1080]],
        "mesh_warp": "grid_5x5_curved.json",
        "brightness": 1.0,
        "zones": [
          {
            "id": "zone_left_wall",
            "content_rect": {"x": 0, "y": 0, "width": 1920, "height": 1080},
            "mask": "wall_mask.png"
          }
        ]
      },
      {
        "id": "proj_right",
        "output": "strip_2",
        "corner_pin": [[0,0], [1920,0], [1920,1080], [0,1080]],
        "edge_blend": {
          "enabled": true,
          "overlap_left": {"width": 200, "feather": 0.5},
          "brightness_match": 0.95
        }
      },
      {
        "id": "proj_center_stacked",
        "output": "strip_3",
        "stacking": {
          "enabled": true,
          "stack_with": "proj_center_base",
          "sync_mode": "frame_lock",
          "brightness_boost": 1.8
        }
      }
    ]
  }
}
```

---

### 4.3 ğŸ¥ Multi-Video-Routing per Art-Net-Objekt (~20-28h)

- [ ] **Grundidee:** Mehrere Videos gleichzeitig, jedes LED-Objekt bekommt eigenes Video/Generator
- [ ] **Architektur:**
  - Mehrere Player-Instanzen parallel (Video1, Video2, Video3)
  - LED-Objekte definieren (Name, Universe-Range, Pixel-Count)
  - Routing-Config: `{"object": "strip_1", "video_player_id": "video_1"}`
  
- [ ] **Kartendeck-UI mit Slot-Compositing:**
  - **Slot-Struktur (Kartendeck-Metapher):**
    - Slot = Playlist-Position mit gestapelten Clip-Alternativen (wie Kartendeck ğŸ´)
    - Minimiert: Zeigt Icon + Anzahl (`[3 Clips] ğŸ´`)
    - Ausklappen: Zeigt alle Clips im Stack mit Compositing-Settings
  
  - **Compositing innerhalb eines Slots:**
    - Alle Clips im Slot laufen parallel (Layer-Stack)
    - Werden automatisch Ã¼bereinander komponiert
    - Jeder Clip hat eigene Effect-Chain
    - Blend Mode pro Clip (Normal, Multiply, Screen, Overlay, Add, Subtract)
    - Opacity pro Clip (0-100%)
    - Layer-Reihenfolge via Drag & Drop Ã¤nderbar
  
  - **Sequential zwischen Slots:**
    - Slot 1 â†’ Slot 2 â†’ Slot 3 (mit Transitions)
    - Transition-Effekte zwischen Slots (Fade, Wipe, Dissolve, etc.)
    - Auto-Next oder manueller Trigger (Button/Keyboard/MIDI)
    - Loop-Mode fÃ¼r Slot-Sequenz
  
  - **Trigger-Modi pro Slot:**
    - **Manual:** Button-Click oder Keyboard (Nummerntaste)
    - **Auto:** Nach Duration automatisch zum nÃ¤chsten Slot
    - **Random:** ZufÃ¤lliger Slot aus Sequenz
    - **MIDI:** MIDI-Note triggert spezifischen Slot
  
  - **Pro Clip im Slot:**
    - Eigene Effect-Chain
    - Blend Mode & Opacity (fÃ¼r Compositing)
    - Weight fÃ¼r Random-Auswahl (bei mehreren Clips)
    - Auto-Loop oder Play-Once
  
  - **Pro Slot:**
    - Name/Label (z.B. "Intro Varianten", "Drop", "Outro")
    - Duration (fÃ¼r Auto-Mode)
    - Transition zum nÃ¤chsten Slot (Type + Duration)
    - Output-Routing (LED-Objekt-Zuweisung)
    - Enable/Disable Toggle

- [ ] **Implementierung:**
  - Phase 1: LED-Objekt-Definition & Config (~2h)
  - Phase 2: Slot-Manager (Slot-Sequenz, Trigger-System) (~3h)
  - Phase 3: Layer-Compositor fÃ¼r Slot-Compositing (Blend Modes, Opacity) (~3h)
  - Phase 4: Transition-System zwischen Slots (~2h)
  - Phase 5: Routing-System & Frame-Collection (~2h)
  - Phase 6: API-Endpoints (Slot CRUD, Clip Management, Trigger) (~3h)
  - Phase 7: UI (Kartendeck-View, Ausklapp-Mechanik, Compositing-Controls) (~5h)

**JSON-Config Beispiel:**
```json
{
  "led_objects": [
    {"name": "strip_left", "universes": [1,2], "pixels": 200},
    {"name": "strip_right", "universes": [3,4], "pixels": 200},
    {"name": "panel_center", "universes": [5,6], "pixels": 256}
  ],
  "slots": [
    {
      "slot_id": 1,
      "name": "Intro Varianten",
      "duration": 30,
      "clips": [
        {
          "path": "intro_v1.mp4",
          "effects": [{"plugin_id": "blur", "params": {"strength": 2.0}}],
          "blend_mode": "normal",
          "opacity": 100,
          "layer_order": 0
        },
        {
          "path": "generator:plasma",
          "effects": [],
          "blend_mode": "multiply",
          "opacity": 50,
          "layer_order": 1
        }
      ],
      "transition_to_next": {"type": "fade", "duration": 1.5},
      "output_routing": {"led_object": "strip_left"}
    },
    {
      "slot_id": 2,
      "name": "Drop Section",
      "duration": 60,
      "clips": [
        {"path": "drop_bg.mp4", "blend_mode": "normal", "opacity": 100},
        {"path": "generator:fire", "blend_mode": "screen", "opacity": 70},
        {"path": "overlay.mp4", "blend_mode": "add", "opacity": 40}
      ],
      "transition_to_next": {"type": "wipe_left", "duration": 0.5},
      "output_routing": {"led_object": "strip_left"}
    }
  ]
}
```

---

### 4.4 ğŸ–¥ï¸ Video Wall Slicing Support (~8-12h)

- [ ] **Multi-Display Video Slicing (8-12h):**
  - **Grundidee:** Ein Video auf mehrere Displays/LED-Matrizen aufteilen
  - **Slice Configuration:**
    - Definition von Slice-Bereichen (x, y, width, height)
    - Zuweisung von Slices zu LED-Objekten/Displays
    - Grid-basierte Slice-Definition (z.B. 3x2 Grid = 6 Displays)
    - Custom Slice-Bereiche fÃ¼r unregelmÃ¤ÃŸige Layouts
  - **Slice Transform Plugin:**
    - Neuer Effect-Plugin-Typ: `slice_transform`
    - Parameter: `slice_id`, `x_offset`, `y_offset`, `width`, `height`
    - Anwendbar auf Player-Level oder Layer-Level
    - UnterstÃ¼tzt Multi-Layer-Compositing (jeder Layer kann gesliced werden)
  - **Slice Routing:**
    - Mapping: Slice â†’ LED-Objekt/Universe-Range
    - Multi-Player-Support: Verschiedene Slices an verschiedene Player
    - Overlap-Detection: Warnung bei Ã¼berlappenden Slices
  - **Slice Map Visualisierung:**
    - Separate HTML-Page: `slice-mapper.html`
    - Visual Grid-Editor mit Drag & Drop
    - Live-Preview aller Slices
    - Export/Import von Slice-Konfigurationen
  - **Implementierung:**
    - Phase 1: Slice Configuration Schema (~1h)
    - Phase 2: Slice Transform Plugin (~2h)
    - Phase 3: Slice Routing Engine (~2h)
    - Phase 4: API-Endpoints (Slice CRUD) (~1h)
    - Phase 5: Slice Map Visualisierung (~3h)
    - Phase 6: Live-Preview Integration (~1h)

**Use-Cases:**
- LED-Matrix-WÃ¤nde (z.B. 6x 60x300 Pixel = 180x300 Video Wall)
- Multi-Display-Setups (3x2 Monitore als eine groÃŸe FlÃ¤che)

**Config-Beispiel:**
```json
{
  "video_wall": {
    "slices": [
      {
        "id": "slice_top_left",
        "source_rect": {"x": 0, "y": 0, "width": 60, "height": 150},
        "target": "strip_1",
        "universes": [1, 2]
      },
      {
        "id": "slice_top_right",
        "source_rect": {"x": 60, "y": 0, "width": 60, "height": 150},
        "target": "strip_2",
        "universes": [3, 4]
      },
      {
        "id": "slice_bottom_left",
        "source_rect": {"x": 0, "y": 150, "width": 60, "height": 150},
        "target": "strip_3",
        "universes": [5, 6]
      },
      {
        "id": "slice_bottom_right",
        "source_rect": {"x": 60, "y": 150, "width": 60, "height": 150},
        "target": "strip_4",
        "universes": [7, 8]
      }
    ]
  }
}
```

---

## ğŸ¨ PRIORITÃ„T 5 - Niedrig-Komplex, Niedrig-PrioritÃ¤t (~14-20h)
**Maintenance, Polishing, Nice-to-have**

### 5.1 ğŸ”Œ Plugin-System (Optional) (~2-3h)

- [ ] **Preset System fÃ¼r Effect Parameters (2-3h):**
  - Effect-Preset-Speicherung (Name + Parameter-Werte)
  - Preset-Library pro Effect-Plugin
  - UI: Save/Load/Delete Presets im Effect-Panel
  - API: `/api/effects/<effect_id>/presets` CRUD
  - Dokumentation: `docs/EFFECT_PRESETS.md`

---

### 5.2 ğŸ¨ GUI-Optimierungen (~12-18h)

- [ ] **Art-Net Preview Expansion (4-6h):**
  - **Realtime LED Object Visualization:**
    - Live-View aller LED-Objekte mit aktuellen Farben
    - 2D-Representation: LED-Strip/Matrix als Pixel-Reihe
    - Farbcodierung: RGB-Werte als colored boxes
    - Auto-Update: 10-30 FPS live refresh
  - **Object-List View:**
    - Universe-Info pro Objekt (Universe 1-4, etc.)
    - Pixel-Count & Status (Online/Offline)
    - DMX-Address-Range anzeigen
  - **Features:**
    - Toggle zwischen Compact-View (Icons) und Expanded-View (Full Colors)
    - Click auf Objekt â†’ Highlight in Preview
    - Color-Picker: Click auf Pixel â†’ zeigt RGB-Wert
    - Performance-Mode: Reduced FPS bei niedriger CPU
  - **Implementierung:**
    - Phase 1: WebSocket fÃ¼r Live-DMX-Data (~2h)
    - Phase 2: Canvas-Renderer fÃ¼r LED-Objects (~2h)
    - Phase 3: UI-Controls & Toggle (~1h)
    - Phase 4: Performance-Optimierung (~1h)

- [ ] **Drag & Drop Layout-Editor:**
  - GridStack.js Integration
  - Panels frei verschieben & resizen
  - LocalStorage-Persistierung
  - Preset-Layouts: "Standard", "Video-Focus", "Compact"

---

### 5.3 ğŸ§ª Testing & Verification

- [ ] **Milkdrop via Screencapture testen:**
  - Screencapture-Generator mit Milkdrop/projectM-Fenster
  - Region-Capture fÃ¼r optimale Performance
  - Alternative: Window-Capture API

- [x] **Multi-Layer System Testing (~2-4h):** âœ… COMPLETED (2025-12-02)
  - âœ… Run `tests/test_api_layers.py` to verify all tests pass
  - âœ… Test live multi-layer playback with different FPS sources
    - âœ… Verify: Overlay lÃ¤uft nicht doppelt so schnell bei hÃ¶herer FPS
    - âœ… Verify: Frame-Skipping funktioniert bei niedrigerer FPS
  - âœ… Verify snapshot restore with layers
  - âœ… Test generator + video layer combinations
  - âœ… Test layer with effects + blend modes
  - âœ… Test autoplay with multi-layer clips
  - âœ… Test transitions on layer 0 with overlays active

### 5.4 ğŸ› ï¸ Weitere Verbesserungen

- [ ] **File Browser Thumbnails (~6-10h):**
  - **Thumbnail Generation:**
    - Video: Erstes Frame als Thumbnail (FFmpeg -ss 0 -vframes 1)
    - Image: Resized Preview (Pillow/OpenCV)
    - Cache-System: Thumbnails in `data/thumbnails/` speichern
    - Lazy-Loading: Thumbnails on-demand generieren
  - **UI Features:**
    - Toggle-Button: Enable/Disable Thumbnail-Anzeige
    - List-View: Thumbnail neben Dateinamen (50x50px)
    - Tree-View: Thumbnail neben File-Icon (40x40px)
    - Hover-Popup: GrÃ¶ÃŸeres Preview (200x200px) bei Mouse-Hover
    - Loading-State: Spinner wÃ¤hrend Thumbnail-Generation
  - **Performance:**
    - Thumbnail-Size: 100x100px (JPEG, 85% QualitÃ¤t)
    - Max. Generation-Time: 500ms pro Video
    - Batch-Generation: API-Endpoint `/api/files/thumbnails/generate`
    - Cache-Cleanup: Alte Thumbnails nach 30 Tagen lÃ¶schen
  - **Implementation:**
    - Phase 1: Thumbnail-Generator (FFmpeg + Pillow) (~2h)
    - Phase 2: Cache-System & API (~2h)
    - Phase 3: FilesTab UI Integration (~2h)
    - Phase 4: Toggle & Settings (~1h)

- [ ] **VollstÃ¤ndige Player/Playlist-Generalisierung (~8-12h):**
  - Hardcodierte Playlist-Arrays entfernen (`videoFiles`, `artnetFiles`)
  - Hardcodierte Current-Item-IDs zu `playerConfigs[playerId].currentItemId` migrieren
  - Spezifische Lade-Funktionen (`loadVideoFile`, `loadArtnetFile`) durch generische Funktion mit `playerId` Parameter ersetzen
  - HTML/UI dynamisch aus `playerConfigs` generieren (Player-Container, Buttons)
  - Legacy-onclick-Handler (`window.playVideo`, etc.) entfernen und durch generische Event-Handler ersetzen
  - **Ziel:** Neuer Player nur durch HinzufÃ¼gen in `playerConfigs` mÃ¶glich, ohne Code-Ã„nderungen

- [x] **Playlist Playback Refactoring (~4-6h):** âœ… COMPLETED
  - âœ… Ãœberarbeitung Loop/Autoplay/Play-Funktionen
  - âœ… Clip-Add-Handling vereinheitlichen
  - âœ… Auto-Start beim ersten Clip konsistent implementieren
  - âœ… State-Management zwischen Frontend/Backend synchronisieren
  - **Note:** Implemented with session_state.py persistence, autoplay/loop toggles, and consistent clip handling

- [x] **player.js Performance-Optimierung (~6-10h):** âœ… COMPLETED - Already Optimized
  - âœ… **Event-Handler-Leak behoben:** Event-Delegation implementiert (Lines 1689-1936)
    - Memory-Leak behoben durch Event-Delegation Pattern
    - 4 Event-Listener pro Container (statt 15-20 pro Item)
    - Handler Cleanup on Re-Render implementiert
    - **Einsparung: 40-60% Memory**
  - âœ… **Generator-Map fÃ¼r O(1) Lookups:** Map-basierte Lookups implementiert (Lines 21-23, 381, 436)
    - effectsMap und generatorsMap nutzen Map.get() statt Array.find()
    - Alle Hot-Paths verwenden Map-Lookups (Lines 507, 896, 996, 1013)
    - Nur 1x Array.find() Fallback (Line 1718, defensive coding, <1% impact)
    - **Einsparung: 5-10% CPU**
  - âœ… **Unified Update-Loop:** Intelligenter koordinierter Update-Loop (Lines 190-227)
    - Single setInterval (250ms) mit koordinierten Sub-Intervallen
    - Conditional Updates: nur bei Autoplay/Clip-Selection aktiv
    - 3 separate Timer zu 1 koordiniertem Loop kombiniert
    - **Einsparung: 10-15% CPU**
  - âœ… **DOM-Query-Caching:** Minimal querySelector usage
    - Nur 1x querySelectorAll() in dragend (Line 1781, nur bei Drag-Operations)
    - Event-Delegation verhindert wiederholte Queries
    - **Impact: <1% (drag operations sind selten)**
  - âœ… **Bereits implementiert:**
    - Fast-poll fÃ¼r Live-Parameter (500ms updateClipEffectLiveParameters) ohne Re-Rendering
    - Separate Update-Intervalle fÃ¼r Video/Art-Net/Clip-Effects
    - Conditional Updates (nur wenn nÃ¶tig)
  - **Gesamt-Ergebnis:** ~50-75% CPU/Memory Reduction achieved
  - **Dokumentation:** `PERFORMANCE_ANALYSIS_PLAYER.md` (detaillierte Analyse)
  - **Fazit:** âœ… Keine weitere Optimierung notwendig, Performance-Budget erfÃ¼llt

- [x] **Projekt-Struktur Refactoring (~2-3h):** âœ… COMPLETED (2025-12-04)
  - âœ… `src/plugins/` â†’ `plugins/` (nach Root verschoben)
  - âœ… `src/static/` â†’ `frontend/` (nach Root verschoben + umbenannt)
  - **Vorteile:**
    - Klare Trennung: Backend (`src/`) vs Frontend (`frontend/`) vs Plugins (`plugins/`)
    - Bessere Ãœbersicht: Plugins sind Top-Level (wie Config)
    - Standard-Konvention: Viele Projekte nutzen `frontend/` statt `static/`
  - **DurchgefÃ¼hrte Ã„nderungen:**
    - Plugin-Verzeichnis: `plugin_manager.py` nutzt jetzt `plugins/`
    - Flask static_folder: `rest_api.py` zeigt auf `../frontend`
    - Test-Imports: `test_blend_*.py` nutzen `from plugins.effects`
    - Alle Plugin-Dateien nutzen bereits `from plugins import` (keine Ã„nderung nÃ¶tig)

- [ ] Unit Tests erweitern (Player, FrameSource, API)
- [ ] API-Authentifizierung (Basic Auth/Token)
- [ ] PyInstaller EXE Build Setup
- [ ] Environment Variable Support fÃ¼r config.json
- [ ] JSON Schema Validation fÃ¼r config.json
- [ ] Hot-Reload (config.json watcher)
- [ ] Dockerfile erstellen

---

## ğŸ”¬ PRIORITÃ„T 6 - Optional / Langfristig (~64-86h)
**ZukÃ¼nftige Features mit hohem Aufwand**

### 6.1 â±ï¸ Script-basierter Sequenzer (Optional, ~4-6h)

- **Power-User Feature:** Python-DSL fÃ¼r Show-Definition
- **Features:** CLI-Befehl, Script-Loader, Volle Python-Kontrolle
- **Empfehlung:** Nice-to-have, niedrige PrioritÃ¤t

---

### 6.2 ğŸ“ˆ Timeline-Sequenzer (Optional, ~60-80h)

- Upgrade von Playlist-Sequenzer zu visueller Timeline
- Features: Clip-Trimming, Scrubbing, Multi-Track, Audio-Sync
- **Nur bei komplexeren Anforderungen**

---

## ğŸ“Š Zusammenfassung nach PrioritÃ¤t

| PrioritÃ¤t | Aufwand | Nutzen | Summe Stunden |
|-----------|---------|--------|---------------|
| **P1** | Niedrig | Hoch | ~45-69h (+7-10h Unified +2-3h Presets +6-8h WS) |
| **P2** | Mittel-Hoch | Sehr Hoch | ~48-72h (+40-60h Multi-Video Cluster) |
| **P3** | Mittel | Mittel | ~16-31h |
| **P4** | Hoch | Hoch | ~48-76h |
| **P5** | Niedrig | Niedrig | ~12-18h (Presets â†’ P1 verschoben) |
| **P6** | Sehr Hoch | Mittel | ~64-86h |
| **GESAMT** | | | **~233-352h** (+40-60h Multi-Video Cluster)

---

## ğŸ¯ Empfohlene Umsetzungs-Reihenfolge

### Phase 1: Foundation & Performance (P1) - ~45-69h ğŸ”¥ PRIORITY
1. **Unified Playlist System (7-10h)** â† Zuerst! (Basis fÃ¼r alles weitere, -200 Zeilen Code)
2. Master/Slave Playlist Sync (8-14h)
3. Plugin-System erweitern - Layer-Effekte (8-12h)
4. Preset System fÃ¼r Effect Parameters (2-3h)
5. **WebSocket Command Channel (6-8h)** â† Performance-Boost! (20-50x schnellere Commands)
6. Playlist-Sequenzer (8-12h)
7. MIDI-over-Ethernet Support (6-10h)

**Ziel:** Saubere Code-Basis â†’ VollstÃ¤ndige Show-Control â†’ Production-ready Performance

**Warum diese Reihenfolge?**
- **Unified Playlist zuerst:** Bereinigt Code-Basis, macht alle weiteren Features einfacher
- **Master/Slave danach:** Baut auf sauberem Playlist-System auf
- **Layer-Effekte + Presets:** VervollstÃ¤ndigt Plugin-System vor Performance-Optimierung
- **WebSocket am Ende:** Optimiert dann das bereits funktionierende System (85% weniger Server-Load)

---

### Phase 2: Multi-Network (P2) - ~8-12h
1. Multi-Network-Adapter Support

**Ziel:** Multi-Universe Art-Net auf verschiedenen Netzwerk-Interfaces

---

### Phase 3: Content (P3) - ~16-31h
1. Audio-Reactive Support
2. WebRTC Video Preview (optional - nur bei CPU-Problemen)

**Ziel:** Audio-Reactive Effects & Optional Video-Streaming-Optimierung

---

### Phase 4: Advanced (P4) - ~24-40h
1. Multi-Video-Routing mit Kartendeck-UI
2. Neue Frame Sources (ShaderToy, LiveStream)

**Ziel:** Multi-Output-Setups & Advanced Content-Sources

---

### Phase 5+: Polish & Future (P5+P6) - ~78-107h
1. GUI-Optimierungen
2. Maintenance & Tests
3. Optional: Timeline-Sequenzer

**Ziel:** Production-Polishing & Langzeit-Features

---

## ğŸ“š Status (Stand: 2025-12-02)

### âœ… Fertiggestellt (v2.3)
- **Unified API Architecture** mit UUID-basiertem Clip-Management
- **Dual-Player-System** (Video Preview + Art-Net Output)
- **Plugin-System** vollstÃ¤ndig implementiert (PluginBase, PluginManager, API)
- **18 Effect-Plugins:** 11 Farb-Manipulation, 5 Time & Motion, 1 Blur, 1 Blending
- **ClipRegistry** mit UUID-basierter Clip-Identifikation
- **Code-Cleanup** (~1500 Zeilen deprecated Code entfernt)
- **Universal Search Filter** fÃ¼r Effects, Sources, Files (v2.3.1)
- **Multi-Video-Source Support** via `video_sources` config (v2.3.1)
- **Default Effect Chains** via config.json (Player & Clip-Level) (v2.3.1)
- **Transition Plugin System** mit Fade Transition & Reusable UI Component (v2.3.1)
- **Multi-Layer Compositing System** (v2.3.2):
  - Clip-based layers (per playlist item)
  - Layer 0 = base clip (immutable)
  - Overlay layers with blend modes (Normal, Multiply, Screen, Overlay, Add, Subtract)
  - Per-layer opacity control (0-100%)
  - Layer CRUD API (`/api/clips/{clip_id}/layers`)
  - Drag-drop layer management in UI
  - Thread-safe layer loading with auto-reload
  - Session state persistence for layers
- **Clip Trimming System** (v2.3.3):
  - In/Out Points pro Clip mit Non-Destructive Editing
  - Reverse Playback Support
  - Ion.RangeSlider UI mit Collapsible Section
  - Right-Click Reset to Full Range
  - Backend as Source of Truth fÃ¼r Clip IDs
  - Live-Apply bei aktiver Wiedergabe
- **HAP Codec & Universal Video Converter** (v2.3.5):
  - FFmpeg-based video converter mit HAP codec support
  - Multiple output formats: HAP, HAP Alpha, HAP Q, H.264, H.264 NVENC
  - Batch processing mit glob patterns (recursive support)
  - Resize modes: none, fit, fill, stretch, auto
  - Loop optimization mit fade in/out
  - Standalone converter.html page mit dark mode
  - File browser integration (FilesTab component)
  - Drag & drop from file browser and file system
  - Local file upload support
  - Dual-mode selection: Browser Mode vs Pattern Mode
  - Multi-file sequential conversion mit progress tracking
  - Smart path resolution (workspace root + video/ directory)
  - Search filter for file browser (tree + list view)
  - Auto-expand folders when searching

---

*Siehe [HISTORY.md](HISTORY.md) fÃ¼r abgeschlossene Features (v1.x - v2.3)*
